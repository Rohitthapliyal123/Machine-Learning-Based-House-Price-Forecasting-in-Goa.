{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fbaa242-1298-4a55-80d5-e9ec5b3910a5",
   "metadata": {},
   "source": [
    "# Data-Driven Decisions: Predicting Goa House Prices for Smart Investments\n",
    "\n",
    "This project develops a machine learning model designed to accurately predict real estate prices in Goa. By analyzing key features, the model aims to foster a deeper understanding of the Goa housing market, empowering better, data-driven decisions. \n",
    "\n",
    "## Overview \n",
    "This project focuses on building a machine learning model to predict real estate prices in Goa. The model utilizes key features such as location (longitude, latitude, ocean_proximity), housing characteristics (age, total rooms, total bedrooms), and economic indicators (population, households, median income) to estimate the median house value. The goal is to provide a data-driven framework for anticipating the Goa housing market, aiding in informed decision-making for buyers, sellers, and investors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a74d03c-cb2b-478d-a595-10083d5efeed",
   "metadata": {},
   "source": [
    "### 1. Importing required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01abcf67-cf2c-4b6f-b31f-72c958cd6209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import  pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef46e94-3f25-43e7-885a-0749050b1b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files for automating logic with unseen or new data\n",
    "MODEL_FILE = \"Model.pkl\"\n",
    "PIPELINE_FILE = \"pipeline.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e9ae09-4aaf-48f6-9dcf-421a4d58fa67",
   "metadata": {},
   "source": [
    "### 2. Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd262e2d-937d-4fef-8096-f53a48e80710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(num_variables , cat_variables):\n",
    "    # Pipeline logic (Numeric Data preprocessing)\n",
    "    num_pipeline1 = Pipeline([\n",
    "        (\"Imputer\", SimpleImputer(strategy='median')),\n",
    "        (\"Scaling\", StandardScaler())\n",
    "    ])  \n",
    "\n",
    "    # Pipeline logic (Categorical Data preprocessing)\n",
    "    cat_pipeline2 = Pipeline([\n",
    "        (\"Imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoding\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")),\n",
    "        (\"Scaling\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # For merging categorical and numeric data\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        ('numeric', num_pipeline1, num_variables),\n",
    "        ('category', cat_pipeline2, cat_variables),\n",
    "\n",
    "    ])\n",
    "    return full_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc4266-f0a6-418a-81ac-ecf706c2091e",
   "metadata": {},
   "source": [
    "### 3. Main Logic within IF-ELSE clause-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0188cc64-351d-4d2d-9afb-6d6882a5502f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete. Results saved to predicted_data.csv\n"
     ]
    }
   ],
   "source": [
    "# 2) Stratified shuffling and train_test_split\n",
    "\n",
    "if not os.path.exists(MODEL_FILE):\n",
    "\n",
    "    data = pd.read_csv(\"housing.csv\")\n",
    "    # Creating Strata...\n",
    "    data[\"income_cat\"] = pd.cut(data[\"median_income\"] , bins=[0 , 1.9 , 3.8, 5.7, 7.6 , np.inf] , labels=[1 , 2 , 3 , 4 , 5])\n",
    "\n",
    "    # An object of stratified class\n",
    "    split = StratifiedShuffleSplit(n_splits=1 , test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    for train_index, test_index in split.split(data , data[\"income_cat\"]):\n",
    "        strat_train_data = data.loc[train_index].drop(\"income_cat\" , axis= 1)\n",
    "        data.loc[test_index].drop(\"income_cat\" , axis= 1).to_csv(\"input.csv\") # Storing in file for testing\n",
    "\n",
    "    # 3) Now we'll work on training data( but with copy of data for future risk possibilities)\n",
    "\n",
    "    train_data = strat_train_data.copy()\n",
    "\n",
    "    #4) Separate features and labels from training data\n",
    "\n",
    "    labels_data = train_data[\"median_house_value\"].copy()\n",
    "    features_data = train_data.drop(\"median_house_value\" , axis= 1)\n",
    "\n",
    "    # 5) Now, we'll separate numerical and categorical features for different_typed_pipeline_steps\n",
    "\n",
    "    num_cols = features_data.drop(\"ocean_proximity\", axis= 1).columns.tolist()\n",
    "    cat_cols = ['ocean_proximity']\n",
    "\n",
    "    pipeline = build_pipeline(num_cols, cat_cols)\n",
    "    preprocessed_data = pipeline.fit_transform(features_data)\n",
    "\n",
    "    # 7) Train ML Model (Choose Ml model based on performance)\n",
    "    random_reg = RandomForestRegressor(random_state=42)\n",
    "    random_reg.fit(preprocessed_data, labels_data)\n",
    "\n",
    "    # Save models and pipeline\n",
    "    joblib.dump(pipeline, PIPELINE_FILE)\n",
    "    joblib.dump(random_reg, MODEL_FILE)\n",
    "\n",
    "    print(\"Training of model has been done! Congrats...\")\n",
    "else:\n",
    "   # Inference (Future prediction with unseen data.)\n",
    "   model = joblib.load(MODEL_FILE)\n",
    "   pipeline = joblib.load(PIPELINE_FILE)\n",
    "\n",
    "   new_data = pd.read_csv(\"input.csv\").drop([\"median_house_value\" ], axis = 1)\n",
    "\n",
    "   transformed_data = pipeline.fit_transform(new_data)\n",
    "   predictions = model.predict(transformed_data)\n",
    "   new_data[\"median_house_values\"] = predictions\n",
    "\n",
    "   # Now return the output\n",
    "   new_data.to_csv(\"Final Project/predicted_data.csv\" , index=False)\n",
    "   print(\"Inference complete. Results saved to predicted_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13902082-34aa-476f-80d1-0bffd44f1398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03573d-9f8c-48d5-8016-fb5101783be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
